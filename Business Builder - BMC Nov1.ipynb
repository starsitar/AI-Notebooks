{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed90ba89",
   "metadata": {},
   "source": [
    "Pre-processing\n",
    "* Create a chroma DB for this run, embeddings added can be different collections\n",
    "* Create Case Embeddings\n",
    "* Create Business Model Canvas Embeddings\n",
    "* Create Embeddings of 8 Business Types & generic Business Model Canvas Questions for each\n",
    "\n",
    "Business Builder Process\n",
    "Problem Refinement\n",
    "* Refine understanding of the problem, and save to embeddings\n",
    "* Generate Research Questions\n",
    "* Collect relevant initial research for each question as understood and relating to problem. save to embeddings\n",
    "* Create a detailed explanation of problem and present to user for review. Refine as needed\n",
    "\n",
    "Market Research\n",
    "* Generate Market Research Questions\n",
    "* Research and answer market research questions\n",
    "* Search for competitors\n",
    "* Search for market size information\n",
    "\n",
    "Business Model Creation\n",
    "* Create first pass solution\n",
    "* Review first pass solution and create additional research questions\n",
    "* Perform Research\n",
    "* Ask for answers to questions without answers if possible and save as embeddings\n",
    "* Present Final Result\n",
    "\n",
    "Business Refiner\n",
    "* Regenerate solution using embeddings\n",
    "* Ask the users for additional questions\n",
    "* Generate Research Questions\n",
    "\n",
    "\n",
    "\n",
    "Business Financials\n",
    "\n",
    "\n",
    "\n",
    "Pitch Deck Creator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b96871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from apikey import apikey\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.tools import HumanInputRun\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "#logging\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "\n",
    "#Memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks import FileCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks import HumanApprovalCallbackHandler\n",
    "from langchain.tools import ShellTool\n",
    "\n",
    "\n",
    "#Routings and Agents\n",
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', 'AIzaSyDBuRp2A9f40p0_shTopXuzjtV0NvZZzlY')\n",
    "GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID', 'd47965c244e324581')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acc18c",
   "metadata": {},
   "source": [
    "Create Retriever Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e35666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study Retriever\n",
    "#quicker way to load embeddings (update on other sheets)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.load_local(\"faiss_index_cases\", embeddings) #embeddings are created using the create embeddings file\n",
    "llm = OpenAI(temperature=0.6, openai_api_key=apikey)\n",
    "casequery = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=db.as_retriever())\n",
    "retriever=db.as_retriever()\n",
    "\n",
    "case_research = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_state_of_union\",\n",
    "    \"Searches and returns documents regarding the state-of-the-union.\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5812aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business types Retriever (need to create)\n",
    "#quicker way to load embeddings (update on other sheets)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.load_local(\"faiss_index_cases\", embeddings) #embeddings are created using the create embeddings file\n",
    "llm = OpenAI(temperature=0.6, openai_api_key=apikey)\n",
    "casequery = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=db.as_retriever())\n",
    "retriever=db.as_retriever()\n",
    "\n",
    "case_research = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_state_of_union\",\n",
    "    \"Searches and returns documents regarding the state-of-the-union.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8defae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Search Retreiver\n",
    "\n",
    "# Vectorstore\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(), persist_directory=\"./chroma_db_oai\"\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "search = GoogleSearchAPIWrapper()\n",
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm,\n",
    "    search=search,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861c22a",
   "metadata": {},
   "source": [
    "Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd35d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "refineproblem = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"refine this problem described by the user: {instructions}\"\n",
    "    )\n",
    "    | ChatOpenAI(model_name=\"gpt-4\", openai_api_key=apikey, verbose = True)\n",
    "    | StrOutputParser()\n",
    "    | {\"base_response\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "questions = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"ai\", \"{base_response}\"),\n",
    "            (\"system\", \"Generate Research questions to further understand this\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI(model_name=\"gpt-4\", openai_api_key=apikey, verbose = True)\n",
    "    | StrOutputParser()\n",
    "    | {\"research_questions\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "performresearch = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"ai\", \"{research_questions}\"),\n",
    "            (\"system\", \"for each question run the web research tool\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=apikey, verbose = True)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "final_responder = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Generate a final response including scenratio explanation, profit strategy, and trade actions. Explicitly state the input data set values\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI(model_name=\"gpt-4\", openai_api_key=apikey, verbose = True)\n",
    "    | StrOutputParser()\n",
    ")    \n",
    "\n",
    "chain = (\n",
    "    initialanalysis \n",
    "    | {\n",
    "        \"questions\": questions,\n",
    "        \"perform_research\": performresearch,\n",
    "        \"original_response\": itemgetter(\"base_response\"),\n",
    "    }\n",
    "    | final_responder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a1406",
   "metadata": {},
   "source": [
    "Perform Research Chain Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01905710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d53fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ea87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#webresearch tool function\n",
    "\n",
    "class websearchtool(BaseTool):\n",
    "    name = \"web_search\"\n",
    "    description = \"useful for when you need to generate questions and research them on the internet\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return search.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
