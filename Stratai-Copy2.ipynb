{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76034369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prash/.local/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper\n",
    "from apikey import apikey\n",
    "\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.callbacks import FileCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6feb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', 'AIzaSyDBuRp2A9f40p0_shTopXuzjtV0NvZZzlY')\n",
    "GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID', 'd47965c244e324581')\n",
    "\n",
    "search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
    "\n",
    "requests = TextRequestsWrapper()\n",
    "\n",
    "logfile = \"output\"+str(datetime.now())+\".log\"\n",
    "\n",
    "logger.add(logfile, colorize=True, enqueue=True)\n",
    "handler = FileCallbackHandler(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1ca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert resume creator for leadership candidates.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "tradingExpert:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7feea5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container, initial_text=\"\"):\n",
    "        self.container = container\n",
    "        self.text=initial_text\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        # \"/\" is a marker to show difference \n",
    "        # you don't need it \n",
    "        self.text+=token+\"/\" \n",
    "        self.container.markdown(self.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840c6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8721e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686db3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = load_chat_planner(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6322086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = load_agent_executor(model, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d0a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PlanAndExecute(planner=planner, executor=executor, prompt = prompt, callbacks = [handler], verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68398a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n",
      "steps=[Step(value='Identify the cost of the bare metal that Giga is interested in purchasing. This could be a specific type of metal or a general average cost of bare metal.'), Step(value='Divide the total amount of money raised by Giga ($3.8 million) by the cost of the bare metal identified in step 1. This will give the total amount of bare metal that Giga can purchase with its raised funds.'), Step(value=\"Given the above steps taken, please respond to the user's original question by providing the calculated amount of bare metal that Giga can purchase with its $3.8 million raise.\\n\")]\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe human has not provided a specific type of metal that Giga is interested in purchasing. I need to ask for more information to provide an accurate answer. \n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Could you please specify the type of bare metal that Giga is interested in purchasing?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Identify the cost of the bare metal that Giga is interested in purchasing. This could be a specific type of metal or a general average cost of bare metal.\n",
      "\n",
      "Response: Could you please specify the type of bare metal that Giga is interested in purchasing?\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The assistant needs to divide the total amount of money raised by Giga ($3.8 million) by the cost of the bare metal identified in step 1. However, the cost of the bare metal is not provided. The assistant should ask for this information before proceeding. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Could you please provide the cost of the bare metal identified in step 1?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Divide the total amount of money raised by Giga ($3.8 million) by the cost of the bare metal identified in step 1. This will give the total amount of bare metal that Giga can purchase with its raised funds.\n",
      "\n",
      "Response: Could you please provide the cost of the bare metal identified in step 1?\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user has not provided the cost of the bare metal that Giga is interested in purchasing. Without this information, I cannot calculate the amount of bare metal that Giga can purchase with its $3.8 million raise. I need to ask the user for this information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm sorry, but I can't provide the calculated amount of bare metal that Giga can purchase with its $3.8 million raise without knowing the cost of the bare metal. Could you please provide this information?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Given the above steps taken, please respond to the user's original question by providing the calculated amount of bare metal that Giga can purchase with its $3.8 million raise.\n",
      "\n",
      "\n",
      "Response: I'm sorry, but I can't provide the calculated amount of bare metal that Giga can purchase with its $3.8 million raise without knowing the cost of the bare metal. Could you please provide this information?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent(\"how much bare metal can giga buy with its 3.8 million raise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c789914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
